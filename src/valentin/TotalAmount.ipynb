{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_path = '../../big_data/rb-suppliers-challange/receipts.csv'\n",
    "texts_path = '../../big_data/rb-suppliers-challange/texts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_path, index_col=['id'])\n",
    "\n",
    "dataset = dataset[~dataset.supplier_name.isnull()]\n",
    "dataset = dataset[~dataset.currency_code.isnull()]\n",
    "np.random.seed(1)\n",
    "shuffled = dataset.reindex(np.random.permutation(dataset.index))\n",
    "\n",
    "unique_supplier_names = shuffled.supplier_name.unique()\n",
    "unique_currency_codes = shuffled.currency_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_names = [f.split(\".\")[0] for f in listdir(texts_path) if isfile(join(texts_path, f)) and f.endswith('.json')]\n",
    "ids = np.array(list(set([int(f) for f in file_names]).intersection(set(dataset.index.values))))\n",
    "texts = pd.Series(['' for i in ids], index=ids)\n",
    "for index in ids:\n",
    "    json_data = open(texts_path + str(index) + '.json', encoding=\"utf8\")\n",
    "    data = json.load(json_data)\n",
    "    try:\n",
    "        texts[index] = data[0]['textAnnotations'][0]['description']\n",
    "    except:\n",
    "        texts[index] = ''\n",
    "dataset['texts'] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prices = pd.Series([[] for i in ids], index=ids)\n",
    "for index in ids:\n",
    "    text = dataset['texts'][index]\n",
    "    total_amount = dataset['total_amount'][index]\n",
    "    lines = text.split('\\n')\n",
    "    current_prices = []\n",
    "    for line in lines:\n",
    "        found_prices = re.findall('\\d[\\d\\.,]+', line)\n",
    "        found_digits = re.findall('\\d', line)\n",
    "        if len(found_prices) >= 1:\n",
    "            for item in found_prices:\n",
    "                try:\n",
    "                    current_price = float(item)\n",
    "                except:\n",
    "                    break\n",
    "                \n",
    "                new_price = dict()\n",
    "                new_price['value'] = current_price\n",
    "                new_price['line'] = line\n",
    "                new_price['is_total'] = 1 if current_price == total_amount else 0\n",
    "                new_price['has_dot'] = '.' in line\n",
    "                new_price['has_comma'] = ',' in line\n",
    "                new_price['has_total_word'] = 'total' in line.lower()\n",
    "                new_price['digits_count'] = len(found_digits)\n",
    "                \n",
    "                current_prices.append(new_price)\n",
    "    \n",
    "    for i, price in enumerate(current_prices):\n",
    "        if len(current_prices) == 1:\n",
    "            price['order'] = 1.00\n",
    "        else:\n",
    "            price['order'] = round(i / (len(current_prices) - 1), 2)\n",
    "        \n",
    "    prices[index] = current_prices\n",
    "    \n",
    "dataset['prices'] = prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_data = []\n",
    "Y_data = []\n",
    "\n",
    "for id_index in ids:\n",
    "    for price_index, price in enumerate(dataset['prices'][id_index]):\n",
    "        # new_index = str(id_index) + '_' + str(price_index)\n",
    "        \n",
    "        features = []\n",
    "        features.append(price['has_dot'])\n",
    "        features.append(price['has_comma'])\n",
    "        features.append(price['has_total_word'])\n",
    "        features.append(price['digits_count'])\n",
    "        features.append(price['order'])\n",
    "        X_data.append(features)\n",
    "        \n",
    "        Y_data.append(1 if price['is_total'] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_items_count = int(len(X_data) * (10 / 100))\n",
    "X_train =  np.array(X_data[test_items_count:])\n",
    "X_test = np.array(X_data[:test_items_count])\n",
    "Y_train = np.array(Y_data[test_items_count:])\n",
    "Y_test = np.array(Y_data[:test_items_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_amount_classifier = RandomForestClassifier()\n",
    "total_amount_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-28a351f05b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpredictions_for_non_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Average for totals: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_for_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_for_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Average for non totals: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_for_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_for_non_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "predictions_for_total = []\n",
    "predictions_for_non_total = []\n",
    "for x_t, y_t in zip(X_test, Y_test):\n",
    "    predicted = total_amount_classifier.predict_proba(x_t.reshape(1, -1))\n",
    "    if y_t == 1:\n",
    "        predictions_for_total.append(predicted[1])\n",
    "    else:\n",
    "        predictions_for_non_total.append(predicted[1])\n",
    "            \n",
    "print('Average for totals: ', float(sum(predictions_for_total)) / len(predictions_for_total))\n",
    "print('Average for non totals: ', float(sum(predictions_for_total)) / len(predictions_for_non_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
